#!/usr/bin/env ruby
require 'gli'
require 'wmonk'

include GLI::App

program_desc 'Make a static copy of one or more websites'

version Wmonk::VERSION

desc 'Be verbose'
switch [:v,:verbose]

desc 'Specify working folder'
arg_name 'folder', :optional
default_value "."
flag [:p,:pathname]

desc 'Initialize a folder to copy a website'
long_desc <<EOS
Create folder if it does not exist.  Populate folder with project configuration file.
EOS

arg_name 'seed URL(s)'
command :init do |c|
  c.desc 'Augment seed URLs with well known files'
  c.switch [:a, :augment]

  c.action do |global,options,args|
    raise "no seed URLs supplied" if args.length == 0
    root_urls = Wmonk.root_urls(args)
    seed_urls = args
    if options[:augment]
      root_urls.each do |url|
        Wmonk.well_known_files.each do |path|
          url = URI.parse(url.to_s)
          url.path = path
          seed_urls << url.to_s
        end
      end
    end
    project = Wmonk::Project.create(global[:pathname], root_urls: root_urls, seed_urls: args)
    Wmonk::Copy.new(project.path).create
  end
end

desc 'Spider the website'
long_desc <<EOS
Spider the website and create a local copy of the website responses.
EOS

# TODO: gracefully handle Ctrl-C (close SQLite3 database)
# TODO: if SQLite3 database exists, re-get URLs as initial URLs

command :spider do |c|
  c.action do |global,options,args|
    project = Wmonk::Project.open(global[:pathname])

    # TODO: populate Urls from configuration
    puts project.seed_urls
    Anemone.crawl(project.seed_urls, verbose: true) do |anemone|
      copy = Wmonk::Copy.new(project.path)
      storage = anemone.storage = Wmonk::AnemoneStorage.new

      anemone.on_every_page do |page|
        puts "on_every_page: #{page.url} (#{page.code}) #{page.content_type} length: #{page.body.length} => processing (on_every_page)" #if global[:verbose]
        storage[page.url] = page
      end

      anemone.focus_crawl { |page|
        puts "focus_crawl: #{page.url} => processing (focus_crawl)" #if global[:verbose]

        links = []
        unless page.data.exchange_id.nil?
          exchange = Exchange.find_by(id: page.data.exchange_id)
          links = exchange.links
          links.reject! {|link| !project.url_in_scope?(link)}
          links.uniq
        end

        puts "focus_crawl: #{page.url} contains #{links.count} links" #if global[:verbose]
        links
      }
    end
  end
end

desc 'Serve information about and copy of website from static copy'
long_desc <<EOS
View information and static copy of website from a web browser.
EOS

command :serve do |c|
  c.desc 'Port from which to serve information about website'
  c.switch [:p, :port]

  c.action do |global,options,args|
    project = Wmonk::Project.open(global[:pathname])
    copy = Wmonk::Copy.new(project.path)
    Wmonk::Server.new(project, type: :info).start
  end
end

pre do |global,command,options,args|
  # Pre logic here
  # Return true to proceed; false to abort and not call the
  # chosen command
  # Use skips_pre before a command to skip this block
  # on that command only
  puts "Requested pathname for working folder: #{global[:pathname]}" if global[:verbose]
  if File.exists? global[:pathname]
    puts "Pathname exists" if global[:verbose]
    if File.directory? global[:pathname]
      puts "Pathname is a folder" if global[:verbose]
    else
      raise "pathname for working folder is not a folder - #{global[:pathname]}"
    end
  else
    puts "Pathname does not exist" if global[:verbose]
  end
  true
end

post do |global,command,options,args|
  # Post logic here
  # Use skips_post before a command to skip this
  # block on that command only
end

on_error do |exception|
  # Error logic here
  # return false to skip default error handling
  true
end

exit run(ARGV)
